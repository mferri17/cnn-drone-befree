{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08 Back to Regression + batch generator.ipynb","provenance":[],"authorship_tag":"ABX9TyNS1Z5/Wv/YzkbbOfcLC2Ef"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KWeCwnGy3Nv5"},"source":["# Back to Regression | proximity-quadrotor-learning\n","\n","https://github.com/idsia-robotics/proximity-quadrotor-learning"]},{"cell_type":"markdown","metadata":{"id":"b4h76ogI3HqQ"},"source":["## Settings"]},{"cell_type":"code","metadata":{"id":"c-GaBD6g8Wig","executionInfo":{"status":"ok","timestamp":1603656397932,"user_tz":-60,"elapsed":5148,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}},"outputId":"fbbd01f8-dd91-4cdd-8fea-13e6ce47677b","colab":{"base_uri":"https://localhost:8080/","height":159}},"source":["################################\n","### KNOWN IMPORTS\n","######\n","\n","import math\n","import os\n","import time\n","import errno\n","import random\n","import sys\n","import gc\n","from datetime import datetime\n","\n","# %tensorflow_version 1.x\n","import tensorflow as tf\n","\n","# when importing keras, please notice:\n","#   https://stackoverflow.com/a/57298275/10866825\n","#   https://www.pyimagesearch.com/2019/10/21/keras-vs-tf-keras-whats-the-difference-in-tensorflow-2-0/\n","\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import plot_model, to_categorical\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n","\n","# !pip install resnet\n","# import resnet as kr\n","\n","import numpy as np\n","import pandas as pd\n","import sklearn as sk\n","import sklearn.metrics\n","\n","import cv2\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","%matplotlib inline\n","\n","# -- for GradCAM\n","!pip install tf-keras-vis\n","from tf_keras_vis.utils import normalize\n","from tf_keras_vis.gradcam import Gradcam\n","from matplotlib import cm\n","\n","\n","################################\n","### PATHS\n","######\n","\n","# this file goes into the 'PROJECT_ROOT/src/' folder to work properly with the following paths\n","\n","try:\n","  import google.colab\n","  IN_COLAB = True\n","  from google.colab import drive\n","  from google.colab.patches import cv2_imshow\n","  drive.mount('/content/drive')\n","  %cd '/content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/'\n","except:\n","  IN_COLAB = False\n","  from cv2 import imshow as cv2_imshow\n","\n","\n","this_folder = os.path.realpath('.') # see https://stackoverflow.com/a/32711758/10866825 for details\n","lib_folder = os.path.join(this_folder, './lib/')\n","original_models_folder = os.path.join(this_folder, './../dev-models/_originals/') # Dario's original trained models (https://drive.switch.ch/index.php/s/Idsyf8WIwQpvRMF)\n","original_datasets_folder = os.path.join(this_folder, './../dev-datasets/_originals/') # Dario's original dataset (https://drive.switch.ch/index.php/s/8clDQNH645ZjWDD)\n","backgrounds_folder = os.path.join(this_folder, './../dev-datasets/_backgrounds/')\n","new_models_folder = os.path.join(this_folder, './../dev-models/')\n","new_datasets_folder = os.path.join(this_folder, './../dev-datasets/')\n","visualization_folder = os.path.join(this_folder, './../dev-visualization/')\n","\n","dario_model_path = original_models_folder + 'v1_model_train_size_50000_rep_1.h5'\n","dario_train_path = original_datasets_folder + 'dario/v1_train.pickle'\n","dario_test_path = original_datasets_folder + 'dario/v1_test.pickle'\n","\n","\n","\n","################################\n","### CUSTOM IMPORTS\n","######\n","\n","sys.path.append(lib_folder)\n","import general_utils\n","import keras_utils\n","\n","import importlib\n","importlib.reload(general_utils)\n","importlib.reload(keras_utils)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tf-keras-vis in /usr/local/lib/python3.6/dist-packages (0.5.3)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from tf-keras-vis) (2.4.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tf-keras-vis) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tf-keras-vis) (1.18.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from tf-keras-vis) (7.0.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<module 'keras_utils' from '/content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./lib/keras_utils.py'>"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"2n1L9HD1FUyY"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"-85jb7mcq89l","executionInfo":{"status":"ok","timestamp":1603656482668,"user_tz":-60,"elapsed":88400,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}},"outputId":"06f7869d-ee31-4a09-b6c0-43717ee34981","colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["## Generate dataset folder for batch generator\n","\n","bp = visualization_folder + 'maskRCNN/'\n","pps =  [\n","  '20201017_180347 detections orig_train start0 total24215/maskrcnn final - detections orig start0 total24000.npy',\n","  '20201016_183639 detections orig_train start24000 total31863/maskrcnn final A - detections orig start24000 total15500.npy',\n","  '20201016_183639 detections orig_train start24000 total31863/maskrcnn final B - detections orig start24000 total15500.npy',\n","  '20201017_200003 detections orig_train start55000 total8726/maskrcnn final - detections orig start55000 total8720.npy'\n","]\n","dataset_name = 'orig_train'\n","\n","print('loading...')\n","parts = [np.load(bp + pp, allow_pickle=True) for pp in pps]\n","print('loaded')\n","\n","dataset = np.hstack(tuple(parts[:]))\n","print('dataset shape', np.shape(dataset))\n","print(dataset[np.random.randint(len(dataset))].keys())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["loading...\n","loaded\n","dataset shape (63720,)\n","dict_keys(['image', 'centr', 'bbox', 'mask', 'gt'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XD0LecGq1vjS","executionInfo":{"status":"ok","timestamp":1603632599427,"user_tz":-60,"elapsed":1126,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}}},"source":["import shutil\n","\n","shutil.rmtree(dataset_folder)"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"id":"d5esiNKG2fM4","executionInfo":{"status":"ok","timestamp":1603632602797,"user_tz":-60,"elapsed":930,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}}},"source":["print(os.path.exists(dataset_folder))\n","general_utils.create_folder_if_not_exist(dataset_folder)"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_BNQlxw2xDg","executionInfo":{"status":"ok","timestamp":1603656500966,"user_tz":-60,"elapsed":1557,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}},"outputId":"81901171-ad6d-424c-d3aa-b6d39ade32c6","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(os.listdir(dataset_folder))"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["256"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"MLrgoJvzsEip"},"source":["dataset_size = len(dataset)\n","dataset_folder = os.path.join(new_datasets_folder, 'maskrcnn_batch', '{} {}/'.format(dataset_name, dataset_size))\n","general_utils.create_folder_if_not_exist(dataset_folder)\n","\n","print('Exporting in {}\\n'.format(dataset_folder)) \n","\n","for id, frame in enumerate(dataset[:300]):\n","  frame_name = '{} - frame {:06}.npy'.format(dataset_name, id)\n","  frame_path = os.path.join(dataset_folder, frame_name)\n","  frame['id'] = id\n","  np.save(frame_path, frame, allow_pickle=True)\n","\n","  if id % 5000 == 0:\n","    print('Progress {}/{}'.format(id, dataset_size))\n","    print(frame_path)\n","\n","print('\\nExport finished.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TucUrW6BFXlL","executionInfo":{"status":"ok","timestamp":1603648433743,"user_tz":-60,"elapsed":30548,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}},"outputId":"64e1afa0-e4bb-48cf-f86a-5ef5b7f78ce2","colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["# def get_dataset(pickle_path, dataset_start_index = 0, dataset_keep_ratio = 0.5):\n","\n","#   print('Reading dataset from ' + pickle_path)\n","  \n","#   dataset = pd.read_pickle(pickle_path).values\n","#   print('dataset original shape: ' + str(dataset.shape))\n","\n","#   keep = dataset_start_index + int(len(dataset) * dataset_keep_ratio)\n","#   dataset = dataset[dataset_start_index:keep] # reducing dataset size\n","#   print('dataset keep shape: \\t' + str(dataset.shape))\n","#   gc.collect()\n","\n","#   img_data = dataset[:, 0]\n","#   image_size = img_data[0].shape\n","\n","#   x_data = 255 - img_data\n","#   x_data = np.vstack(x_data[:]).astype(np.float32)\n","#   x_data = np.reshape(x_data, (-1, image_size[0], image_size[1], image_size[2]))\n","\n","#   y_data = dataset[:, 1]\n","#   y_data = np.vstack(y_data[:]).astype(np.float32)\n","\n","#   odom_data = dataset[:, 2]\n","#   odom_data = np.vstack(odom_data[:]).astype(np.float32)\n","\n","#   print('img_data shape: \\t' + str(img_data.shape))\n","#   print('x_data shape: \\t\\t' + str(x_data.shape))\n","#   print('y_data shape: \\t\\t' + str(y_data.shape))\n","#   print('odom_dataset shape: \\t' + str(odom_data.shape))\n","\n","#   return img_data, x_data, y_data, odom_data\n","\n","\n","\n","# dario_img, dario_x, dario_y, _ = get_dataset(dario_train_path, 0, 0.1)"],"execution_count":73,"outputs":[{"output_type":"stream","text":["Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/_originals/dario/v1_train.pickle\n","dataset original shape: (63726, 3)\n","dataset keep shape: \t(6372, 3)\n","img_data shape: \t(6372,)\n","x_data shape: \t\t(6372, 60, 108, 3)\n","y_data shape: \t\t(6372, 4)\n","odom_dataset shape: \t(6372, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LAC6CIe4HHbG"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"M8njw8UNqx-B"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"zEUYgRBXNfpZ","executionInfo":{"status":"ok","timestamp":1603655229709,"user_tz":-60,"elapsed":1230,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}}},"source":["def network_create(original_model_path, input_size, regression, classification, retrain_from_layer = None, view_summary = True, view_plot = False):\n","\n","  if not regression and not classification:\n","    raise ValueError(\"At least one between parameter `regression` and `classification` must be True.\")\n","\n","  # --- Network architecture\n","\n","  # input\n","  input_img = Input(shape=(input_size[0], input_size[1], input_size[2]), name = 'input_1')\n","\n","  # start resnet\n","  conv_1 = Conv2D(64, kernel_size=(7,7), strides=(2,2), padding='same', name = 'conv2d_1')(input_img)\n","  batch_1 = BatchNormalization(name = 'batch_normalization_1')(conv_1)\n","  activ_1 = Activation('relu', name = 'activation_1')(batch_1)\n","  pool_1 = MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding='same', name = 'max_pooling2d_1')(activ_1)\n","\n","  # block 1\n","  conv_2 = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', name = 'conv2d_2')(pool_1)\n","  batch_2 = BatchNormalization(name = 'batch_normalization_2')(conv_2)\n","  activ_2 = Activation('relu', name = 'activation_2')(batch_2)\n","  conv_3 = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', name = 'conv2d_3')(activ_2)\n","  add_1 = Add(name = 'add_1')([conv_3, pool_1])\n","\n","  # block 2\n","  batch_3 = BatchNormalization(name = 'batch_normalization_3')(add_1)\n","  activ_3 = Activation('relu', name = 'activation_3')(batch_3)\n","  conv_4 = Conv2D(128, kernel_size=(3,3), strides=(2,2), padding='same', name = 'conv2d_4')(activ_3)\n","  batch_4 = BatchNormalization(name = 'batch_normalization_4')(conv_4)\n","  activ_4 = Activation('relu', name = 'activation_4')(batch_4)\n","  conv_5 = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', name = 'conv2d_5')(activ_4)\n","  conv_6 = Conv2D(128, kernel_size=(1,1), strides=(2,2), padding='valid', name = 'conv2d_6')(add_1)\n","  add_2 = Add(name = 'add_2')([conv_5, conv_6])\n","\n","  # block 3\n","  batch_5 = BatchNormalization(name = 'batch_normalization_5')(add_2)\n","  activ_5 = Activation('relu', name = 'activation_5')(batch_5)\n","  conv_7 = Conv2D(256, kernel_size=(3,3), strides=(2,2), padding='same', name = 'conv2d_7')(activ_5)\n","  batch_6 = BatchNormalization(name = 'batch_normalization_6')(conv_7)\n","  activ_6 = Activation('relu', name = 'activation_6')(batch_6)\n","  conv_8 = Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='same', name = 'conv2d_8')(activ_6)\n","  conv_9 = Conv2D(256, kernel_size=(1,1), strides=(2,2), padding='valid', name = 'conv2d_9')(add_2)\n","  add_3 = Add(name = 'add_3')([conv_8, conv_9])\n","\n","  # end resnet\n","  batch_7 = BatchNormalization(name = 'batch_normalization_7')(add_3)\n","  activ_7 = Activation('relu', name = 'activation_7')(batch_7)\n","  pool_2 = AveragePooling2D(pool_size = (4, 7), strides = (1, 1), padding = 'valid', name = 'average_pooling2d_1')(activ_7)\n","\n","  # dense\n","  flatten_1 = Flatten(name = 'flatten_1')(pool_2)\n","  dense_1 = (Dense(256, activation='relu', name=\"1_dense\"))(flatten_1)\n","  dense_2 = (Dense(128, activation='relu', name=\"2_dense\"))(dense_1)\n","\n","  # targets\n","  y_0 = (Dense(1, activation='linear', name=general_utils.variables_names[0]))(dense_2)\n","  y_1 = (Dense(1, activation='linear', name=general_utils.variables_names[1]))(dense_2)\n","  y_2 = (Dense(1, activation='linear', name=general_utils.variables_names[2]))(dense_2)\n","  y_3 = (Dense(1, activation='linear', name=general_utils.variables_names[3]))(dense_2)\n","  y_4 = (Dense(3, activation='softmax', name=general_utils.variables_names[4]))(dense_2)\n","  y_5 = (Dense(3, activation='softmax', name=general_utils.variables_names[5]))(dense_2)\n","  y_6 = (Dense(3, activation='softmax', name=general_utils.variables_names[6]))(dense_2)\n","  y_7 = (Dense(3, activation='softmax', name=general_utils.variables_names[7]))(dense_2)\n","\n","  outputs = []\n","  if regression:\n","    outputs.extend([y_0, y_1, y_2, y_3])\n","  if classification:\n","    outputs.extend([y_4, y_5, y_6, y_7])\n","\n","  # model\n","  flat_model = Model(inputs = input_img, outputs = outputs) # MODEL\n","\n","  # --- Restore weights from Dario's model \n","\n","  old_model = tf.keras.models.load_model(original_model_path)\n","\n","  for layer in old_model.layers[2:]: # starts at 2 for skipping inputs and nested model\n","    try:\n","      flat_model.get_layer(layer.name).set_weights(layer.get_weights())\n","    except ValueError: # get_layer raises ValueError is a layer does not exist\n","      # for each variable, the respective model only contains the associated variable (so the other outputs will be missing)\n","      print(layer.name, 'layer not found, skipping')\n","      continue \n","\n","  for layer in old_model.get_layer('model_1').layers: # nested model weights\n","    flat_model.get_layer(layer.name).set_weights(layer.get_weights())\n","\n","  # --- Set trainable layers\n","\n","  if retrain_from_layer is not None:\n","    non_trainable_until = retrain_from_layer # non-trainable until specified layer\n","  elif classification:\n","    non_trainable_until = -4 # classification layers always have to be trained\n","  else: # regression\n","    non_trainable_until = len(flat_model.layers) # nothing will be trainable\n","\n","  for layer in flat_model.layers[:non_trainable_until]:\n","    layer.trainable =  False\n","\n","  # --- Result \n","\n","  if view_plot: \n","    plot_model(flat_model, show_shapes = True, expand_nested = True)\n","  if view_summary:\n","    flat_model.summary()\n","    print('Please note that the network is non-trainable until the {} layer.'.format(non_trainable_until))\n","\n","  return flat_model\n","\n","\n","\n","def network_train(model, data_x, data_y, regression, classification, \n","                  batch_size = 64, epochs = 30, verbose = 2,\n","                  validation_split = 0.3, validation_shuffle = True, \n","                  use_lr_reducer = True, use_early_stop = False):\n","\n","  # --- Model settings\n","\n","  loss = []\n","  metrics = []\n","\n","  if regression:\n","    loss.extend(['mean_absolute_error'] * 4)\n","    metrics.append('mse')\n","  if classification:\n","    loss.extend(['categorical_crossentropy'] * 4)\n","    metrics.append('accuracy')\n","\n","  model.compile(loss=loss,\n","                metrics=metrics,\n","                optimizer='adam')\n","\n","  callbacks = []\n","\n","  if use_lr_reducer:\n","    lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=1, patience=4, min_lr=0.1e-6)\n","    callbacks.append(lr_reducer)\n","\n","  if use_early_stop:\n","    early_stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=4, verbose=1)\n","    callbacks.append(early_stop)\n","\n","  # --- Train/Validation split\n","  \n","  n_val = int(len(data_x) * validation_split)\n","  ix_val, ix_tr = np.split(np.random.permutation(len(data_x)), [n_val])\n","  \n","  x_valid = data_x[ix_val, :]\n","  x_train = data_x[ix_tr, :]\n","  y_valid = [var[ix_val] for var in data_y]\n","  y_train = [var[ix_tr] for var in data_y]\n","\n","  # --- Training\n","\n","  history = model.fit(\n","      x = x_train,\n","      y = y_train,\n","      batch_size = batch_size,\n","      epochs = epochs,\n","      validation_data = (x_valid, y_valid),\n","      # validation_split = validation_split,\n","      callbacks = callbacks,\n","      shuffle = True,\n","      verbose = verbose\n","  )\n","\n","  return model, history\n","\n","\n","\n","def network_stats(history, regression, classification):\n","  var_str = 'all_class'\n","\n","  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,6))\n","\n","  # - Loss\n","\n","  ax1.plot(history.history['loss'], 'k--', label='Train Loss')\n","  ax1.plot(history.history['val_loss'], 'k', label='Valid Loss')\n","  ax1.legend(loc='upper right')\n","  ax1.set_xlabel('Epoch')\n","  ax1.set_title(var_str + ' training and validation Loss')\n","\n","  # - Accuracy\n","  \n","  if classification:\n","    ax2.plot(history.history['x_class_accuracy'], 'r--', label='x_class train Accuracy')\n","    ax2.plot(history.history['val_x_class_accuracy'], 'r', label='x_class valid Accuracy')\n","    ax2.plot(history.history['y_class_accuracy'], 'g--', label='y_class train Accuracy')\n","    ax2.plot(history.history['val_y_class_accuracy'], 'g', label='y_class valid Accuracy')\n","    ax2.plot(history.history['z_class_accuracy'], 'b--', label='z_class train Accuracy')\n","    ax2.plot(history.history['val_z_class_accuracy'], 'b', label='z_class valid Accuracy')\n","    ax2.plot(history.history['w_class_accuracy'], 'y--', label='w_class train Accuracy')\n","    ax2.plot(history.history['val_w_class_accuracy'], 'y', label='w_class valid Accuracy')\n","    ax2.legend(loc='lower right')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel('Accuracy')\n","    ax2.set_title(var_str + ' training and validation Accuracy')\n","\n","  plt.show()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d4AKI9nJ-S02"},"source":["### Generator"]},{"cell_type":"code","metadata":{"id":"YjQ_k0t6-b7a","executionInfo":{"status":"ok","timestamp":1603656321634,"user_tz":-60,"elapsed":961,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}}},"source":["def network_train_generator(model, data_folder, regression, classification, augmentation, replace_imgs,\n","                            batch_size = 64, epochs = 30, verbose = 2,\n","                            validation_split = 0.3, validation_shuffle = True,\n","                            use_lr_reducer = True, use_early_stop = False):\n","\n","  # --- Model settings\n","\n","  loss = []\n","  metrics = []\n","\n","  if regression:\n","    loss.extend(['mean_absolute_error'] * 4)\n","    metrics.append('mse')\n","  if classification:\n","    loss.extend(['categorical_crossentropy'] * 4)\n","    metrics.append('accuracy')\n","\n","  model.compile(loss=loss,\n","                metrics=metrics,\n","                optimizer='adam')\n","\n","  callbacks = []\n","\n","  if use_lr_reducer:\n","    lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=1, patience=4, min_lr=0.1e-6)\n","    callbacks.append(lr_reducer)\n","\n","  if use_early_stop:\n","    early_stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=4, verbose=1)\n","    callbacks.append(early_stop)\n","\n","  # --- Train/Validation split\n","\n","  data_files = os.listdir(data_folder)\n","    \n","  from sklearn.model_selection import train_test_split\n","  data_files_train, data_files_valid = train_test_split(data_files, test_size=validation_split, shuffle=validation_shuffle, random_state=1)\n","  size_train, size_valid = len(data_files_train), len(data_files_valid)\n","\n","  # --- Generator\n","  \n","  generator_train = My_Batch_Generator(data_folder, data_files_train, batch_size, regression, classification, augmentation, replace_imgs)\n","  generator_valid = My_Batch_Generator(data_folder, data_files_valid, batch_size, regression, classification, augmentation, replace_imgs)\n","\n","  # --- Training\n","\n","  history = model.fit(\n","      x = generator_train,\n","      steps_per_epoch = int(size_train // batch_size),\n","      validation_data = generator_valid,\n","      validation_steps = int(size_valid // batch_size),\n","      # validation_freq = 10,\n","      epochs = epochs,\n","      callbacks = callbacks,\n","      verbose = verbose\n","  )\n","\n","  return model, history\n","\n","\n","def maskrcnn_transform_networkdata(images, actuals):\n","  image_size = images[0].shape\n","\n","  x_data = 255 - images\n","  x_data = np.vstack(x_data[:]).astype(np.float32)\n","  x_data = np.reshape(x_data, (-1, image_size[0], image_size[1], image_size[2]))\n","\n","  yr = np.transpose(actuals[:,0:4])     # shape (regr_variables, samples) (4, ?)\n","  cat = to_categorical(actuals[:,4:8])  # shape (samples, class_variables, categorical) (?, 4, 3)\n","  yc = np.transpose(cat, (1, 0, 2))     # shape (class_variables, samples, categorical) (4, ?, 3)\n","  y_data = [yr[0], yr[1], yr[2], yr[3], yc[0], yc[1], yc[2], yc[3]]\n","\n","  return x_data, y_data\n","\n","\n","def data_loading(folder, filenames):\n","  loaded = [np.load(os.path.join(folder, fn), allow_pickle=True).item() for fn in filenames]\n","  # print(loaded[0].keys())\n","  # loaded = [[v for k, v in dicty.items()] for dicty in loaded]\n","  # print('dataset transform shape', np.shape(loaded))\n","  return np.array(loaded)\n","\n","\n","def data_augmentation(data, backgrounds):\n","  for frame in data:\n","    bg = np.random.choice(backgrounds, size=(1)) if isinstance(backgrounds, (list, np.ndarray)) and len(backgrounds) > 0 else None\n","    frame['image'] = general_utils.image_background_replace_mask(frame['image'], frame['mask'], transparent=False, replace_bg_images=bg)[0]\n","  return data\n","\n","\n","def data_preprocessing(data, regression, classification):\n","  if not regression and not classification:\n","    raise ValueError(\"At least one between parameter `regression` and `classification` must be True.\")\n","  images = np.array([d['image'] for d in data])\n","  actuals = np.array([d['gt'] for d in data]) # https://stackoverflow.com/a/46317786/10866825\n","  data_x, data_y = maskrcnn_transform_networkdata(images, actuals)\n","  vars = slice(0,8) if regression and classification else (slice(0,4) if regression else slice(4,8))\n","  return data_x, data_y[vars]\n","\n","\n","class My_Batch_Generator(tf.keras.utils.Sequence):\n","  \n","  def __init__(self, folder, files, batch_size, regression, classification, augmentation, backgrounds):\n","    self.folder = folder\n","    self.files = files\n","    self.batch_size = batch_size\n","    self.augmentation = augmentation\n","    self.backgrounds = backgrounds\n","    self.regression = regression\n","    self.classification = classification\n","    \n","  def __len__(self):\n","    return (np.ceil(len(self.files) / float(self.batch_size))).astype(np.int)\n","  \n","  def __getitem__(self, idx):\n","\n","    batch_files = self.files[idx * self.batch_size : (idx+1) * self.batch_size]\n","    # print('batch_files shape', np.shape(batch_files))\n","\n","    batch_data = data_loading(self.folder, batch_files)\n","    # print('batch_data shape', np.shape(batch_data))\n","\n","    batch_augmented = data_augmentation(batch_data, self.backgrounds) if augmentation else batch_data\n","    # print('batch_augmented shape', np.shape(batch_augmented))\n","\n","    batch_x, batch_y = data_preprocessing(batch_augmented, self.regression, self.classification)\n","    # print('batch_x shape', np.shape(batch_x))\n","    # print('batch_y shape', len(batch_y))\n","    \n","    return batch_x, batch_y"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"-k5mRbY6SJg2","executionInfo":{"status":"ok","timestamp":1603656348912,"user_tz":-60,"elapsed":8816,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}},"outputId":"48ccf6c5-afdf-4faa-d758-93dabe494f89","colab":{"base_uri":"https://localhost:8080/","height":496}},"source":["data_folder = os.path.join(new_datasets_folder, 'maskrcnn_batch/orig_train 63720/')\n","input_shape = np.load(os.path.join(data_folder, os.listdir(data_folder)[0]), allow_pickle=True).item()['image'].shape\n","replace_imgs = general_utils.load_images_from_folder(new_datasets_folder + '_backgrounds/backgrounds-20')\n","\n","\n","regression, classification = True, False\n","retrain_from = None\n","augmentation = False\n","\n","model = network_create(dario_model_path, input_shape, regression, classification, retrain_from, view_summary=False)\n","model, history = network_train_generator(model, data_folder, regression, classification, augmentation, replace_imgs, epochs=2)\n","network_stats(history, regression, classification)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","2/2 - 1s - loss: 0.0327 - x_pred_loss: 0.0096 - y_pred_loss: 0.0094 - z_pred_loss: 0.0036 - yaw_pred_loss: 0.0101 - x_pred_mse: 1.7299e-04 - y_pred_mse: 1.5747e-04 - z_pred_mse: 2.0429e-05 - yaw_pred_mse: 2.0183e-04 - val_loss: 0.0260 - val_x_pred_loss: 0.0068 - val_y_pred_loss: 0.0072 - val_z_pred_loss: 0.0032 - val_yaw_pred_loss: 0.0087 - val_x_pred_mse: 7.1946e-05 - val_y_pred_mse: 9.3837e-05 - val_z_pred_mse: 1.7390e-05 - val_yaw_pred_mse: 1.2739e-04\n","Epoch 2/2\n","2/2 - 1s - loss: 0.0327 - x_pred_loss: 0.0096 - y_pred_loss: 0.0094 - z_pred_loss: 0.0036 - yaw_pred_loss: 0.0101 - x_pred_mse: 1.7299e-04 - y_pred_mse: 1.5747e-04 - z_pred_mse: 2.0429e-05 - yaw_pred_mse: 2.0183e-04 - val_loss: 0.0260 - val_x_pred_loss: 0.0068 - val_y_pred_loss: 0.0072 - val_z_pred_loss: 0.0032 - val_yaw_pred_loss: 0.0087 - val_x_pred_mse: 7.1946e-05 - val_y_pred_mse: 9.3837e-05 - val_z_pred_mse: 1.7390e-05 - val_yaw_pred_mse: 1.2739e-04\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1440x432 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"ynfunl-KGpIx"},"source":["# def maskrcnn_extract_network_data(images, actuals):\n","#   image_size = images[0].shape\n","\n","#   x_data = 255 - images\n","#   x_data = np.vstack(x_data[:]).astype(np.float32)\n","#   x_data = np.reshape(x_data, (-1, image_size[0], image_size[1], image_size[2]))\n","\n","#   yr = np.transpose(actuals[:,0:4])     # shape (regr_variables, samples) (4, ?)\n","#   cat = to_categorical(actuals[:,4:8])  # shape (samples, class_variables, categorical) (?, 4, 3)\n","#   yc = np.transpose(cat, (1, 0, 2))     # shape (class_variables, samples, categorical) (4, ?, 3)\n","#   y_data = [yr[0], yr[1], yr[2], yr[3], yc[0], yc[1], yc[2], yc[3]]\n","\n","#   return x_data, y_data\n","\n","\n","# def data_loading(files):\n","#   loaded = [np.load(os.path.join(dataset_folder, fn), allow_pickle=True).item() for fn in files]\n","#   # print(loaded[0].keys())\n","#   # loaded = [[v for k, v in dicty.items()] for dicty in loaded]\n","#   # print('dataset transform shape', np.shape(loaded))\n","#   return np.array(loaded)\n","\n","# def data_augmentation(data, backgrounds):\n","#   for frame in data:\n","#     bg = np.random.choice(backgrounds, size=(1))\n","#     edit = general_utils.image_background_replace_mask(frame['image'], frame['mask'], replace_bg_images=np.random.choice(replace_imgs, size=(1)))[0]\n","#     frame['image'] = edit\n","#   return data\n","\n","# def data_preprocessing(data, regression, classification):\n","#   if not regression and not classification:\n","#     raise ValueError(\"At least one between parameter `regression` and `classification` must be True.\")\n","#   images = np.array([d['image'] for d in data])\n","#   actuals = np.array([d['gt'] for d in data]) # https://stackoverflow.com/a/46317786/10866825\n","#   data_x, data_y = maskrcnn_extract_network_data(images, actuals)\n","#   vars = slice(0,8) if regression and classification else (slice(0,4) if regression else slice(4,8))\n","#   return data_x, data_y[vars]\n","\n","# # ---------------------------------------------------------------------------------------\n","\n","# dataset_folder = os.path.join(new_datasets_folder, 'maskrcnn_batch/orig_train 63720/')\n","# data_files = os.listdir(dataset_folder)\n","  \n","# from sklearn.model_selection import train_test_split\n","# data_files_train, data_files_valid = train_test_split(data_files, test_size=0.3, shuffle=True, random_state=1)\n","# print('data_files_train shape', np.shape(data_files_train))\n","# print('data_files_valid shape', np.shape(data_files_valid))\n","\n","# regression, classification = True, False\n","# replace_imgs = general_utils.load_images_from_folder(new_datasets_folder + '_backgrounds/backgrounds-20')\n","\n","\n","# batch_size = 64\n","# idx = 0\n","\n","# batch_files = data_files_train[idx * batch_size : (idx+1) * batch_size]\n","# print('batch_files shape', np.shape(batch_files))\n","\n","# batch_data = data_loading(batch_files)\n","# print('batch_data shape', np.shape(batch_data))\n","\n","# batch_augmented = data_augmentation(batch_data, replace_imgs)\n","# print('batch_augmented shape', np.shape(batch_augmented))\n","\n","# batch_x, batch_y = data_preprocessing(batch_augmented, regression, classification)\n","# print('batch_x shape', np.shape(batch_x))\n","# print('batch_y shape', len(batch_y))\n","\n","# # ---------------------------------------------------------------------------------------\n","\n","# model = network_create(dario_model_path, batch_x[0].shape, regression, classification, 24, view_summary=False)\n","# model, history = network_train(model, batch_x, batch_y, regression, classification, epochs=10)\n","# network_stats(history, regression, classification)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BMCfoxbD7j8L"},"source":["### Experiment"]},{"cell_type":"code","metadata":{"id":"J4PjuKJkEcmS","executionInfo":{"status":"ok","timestamp":1603655544587,"user_tz":-60,"elapsed":7671,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}},"outputId":"a4579d71-c11b-4e04-f4b9-3c8d7858fb9d","colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["orig_img, orig_x, orig_y, _, _ = general_utils.get_dataset_from_pickle(dario_train_path, 24000, dataset_keep_ratio=0.5)\n","print()\n","\n","# removebg_path = new_datasets_folder + 'MASKRCNN replace 31860 samples (start24000, skip12 = 2655) with 20 backgrounds - total 53100/20201020_091307_maskrcnn_replacebg_df53100_1of1.pickle'\n","# removebg_img, removebg_x, removebg_y, _, _ = general_utils.get_dataset_from_pickle(removebg_path, dataset_keep_ratio=1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/_originals/dario/v1_train.pickle\n","dataset original shape: (63726, 3)\n","dataset keep shape: \t(254, 3)\n","img_data shape: \t(254,)\n","x_data shape: \t\t(254, 60, 108, 3)\n","y_data shape: \t\t(254, 4)\n","odom_dataset shape: \t(254, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (254,)\n","y_data_for_network single classification variable (4:8) \t (254, 3)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G8fzb8aVNJSt","executionInfo":{"status":"ok","timestamp":1603655559327,"user_tz":-60,"elapsed":5746,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}},"outputId":"b0b293ce-a860-4555-d91f-511b0b4c2b51","colab":{"base_uri":"https://localhost:8080/","height":513}},"source":["regression, classification = True, False \n","retrain_from_layer = None\n","\n","vars_interval = slice(0,8) if regression and classification else (slice(0,4) if regression else slice(4,8))\n","train_x = orig_x\n","train_y = orig_y[vars_interval]\n","\n","input_size = train_x[0].shape\n","model = network_create(dario_model_path, input_size, regression, classification, retrain_from_layer, view_summary=False)\n","model, history = network_train(model, train_x, train_y, regression, classification, epochs=2)\n","network_stats(history, regression, classification)\n","\n","gc.collect()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","3/3 - 1s - loss: 0.0423 - x_pred_loss: 0.0094 - y_pred_loss: 0.0095 - z_pred_loss: 0.0048 - yaw_pred_loss: 0.0187 - x_pred_mse: 1.9558e-04 - y_pred_mse: 1.8506e-04 - z_pred_mse: 5.1409e-05 - yaw_pred_mse: 8.7845e-04 - val_loss: 0.0444 - val_x_pred_loss: 0.0112 - val_y_pred_loss: 0.0097 - val_z_pred_loss: 0.0052 - val_yaw_pred_loss: 0.0184 - val_x_pred_mse: 4.4478e-04 - val_y_pred_mse: 2.3273e-04 - val_z_pred_mse: 6.8670e-05 - val_yaw_pred_mse: 7.7464e-04\n","Epoch 2/2\n","3/3 - 1s - loss: 0.0423 - x_pred_loss: 0.0094 - y_pred_loss: 0.0095 - z_pred_loss: 0.0048 - yaw_pred_loss: 0.0187 - x_pred_mse: 1.9558e-04 - y_pred_mse: 1.8506e-04 - z_pred_mse: 5.1409e-05 - yaw_pred_mse: 8.7845e-04 - val_loss: 0.0444 - val_x_pred_loss: 0.0112 - val_y_pred_loss: 0.0097 - val_z_pred_loss: 0.0052 - val_yaw_pred_loss: 0.0184 - val_x_pred_mse: 4.4478e-04 - val_y_pred_mse: 2.3273e-04 - val_z_pred_mse: 6.8670e-05 - val_yaw_pred_mse: 7.7464e-04\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1440x432 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"execute_result","data":{"text/plain":["22951"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"rfSF-XGqRs3a","executionInfo":{"status":"ok","timestamp":1603473708611,"user_tz":-120,"elapsed":602,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}},"outputId":"12fb41e0-de9a-4346-b831-8814e5af7029","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["export_folder = new_models_folder + 'prova/'\n","model_name = 'regression on dario original'\n","keras_utils.network_save(model, export_folder, model_name, None, save_plot = False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model saved in /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-models/prova/regression on dario original - v1_all_class_model.h5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-models/prova/regression on dario original - v1_all_class_model.h5'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"za61Bo81pDoz"},"source":["## Test"]},{"cell_type":"code","metadata":{"id":"jHTo7SaeMU5P","executionInfo":{"status":"ok","timestamp":1603476645838,"user_tz":-120,"elapsed":75464,"user":{"displayName":"Marco Ferri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjolyWq8P5oOjjnycReO9-pz3gHabh0E08D4oDR9Q=s64","userId":"17138480841028725556"}},"outputId":"5795b210-ae92-48cb-cc9e-67b028451388","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from sklearn.metrics import r2_score, mean_squared_error\n","\n","if regression:\n","  dario_path = dario_test_path\n","  bg20_path = new_datasets_folder + 'MASKRCNN replace 11030 samples TEST (start0, skip10 = 1103) with 20 backgrounds - total 22060/20201022_133340_maskrcnn_replacebg_df22060_1of1.pickle'\n","  singlebg_room11_path = new_datasets_folder + 'MASKRCNN replace 11030 samples TEST (skip2) with single_room11 background - total 5515/20201022_131619_maskrcnn_replacebg_df5515_1of1.pickle'\n","  singlebg_room15_path = new_datasets_folder + 'MASKRCNN replace 11030 samples TEST (skip2) with single_room15 background - total 5515/20201022_131716_maskrcnn_replacebg_df5515_1of1.pickle'\n","  singlebg_room20_path = new_datasets_folder + 'MASKRCNN replace 11030 samples TEST (skip2) with single_room20 background - total 5515/20201022_131733_maskrcnn_replacebg_df5515_1of1.pickle'\n","\n","  models_path = ['prova/regression on dario original - v1_all_class_model.h5', 'prova/regression on bg20 retrain24 - v1_all_class_model.h5']\n","  datasets_path = [dario_path, bg20_path, singlebg_room11_path, singlebg_room15_path, singlebg_room20_path]\n","\n","  for mp in models_path:\n","    print('\\n\\n------------------------------------------------------------------------------------------------\\n')\n","    model = tf.keras.models.load_model(new_models_folder + mp)\n","    print('Model imported from', new_models_folder + mp, '\\n\\n')\n","\n","    for dp in datasets_path:\n","      test_img, test_x, test_y, _, _ = general_utils.get_dataset_from_pickle(dp, dataset_keep_ratio=1)\n","      print()\n"," \n","      pred = model.predict(test_x)\n","      for vi in range(4):\n","        y_true = test_y[vi]\n","        y_pred = pred[vi]\n","        print(general_utils.variables_names[vi], 'rmse\\t', np.math.sqrt(mean_squared_error(y_true, y_pred)))\n","        print(general_utils.variables_names[vi], 'r2\\t', r2_score(y_true, y_pred))\n","        print()\n","\n","      evaluate_metrics = model.evaluate(test_x, test_y[vars_interval], batch_size=64, return_dict=True)\n","      print('\\n', evaluate_metrics, '\\n', '\\n')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","------------------------------------------------\n","\n","Model imported from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-models/prova/regression on dario original - v1_all_class_model.h5 \n","\n","\n","Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/_originals/dario/v1_test.pickle\n","dataset original shape: (11035, 3)\n","dataset keep shape: \t(11035, 3)\n","img_data shape: \t(11035,)\n","x_data shape: \t\t(11035, 60, 108, 3)\n","y_data shape: \t\t(11035, 4)\n","odom_dataset shape: \t(11035, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (11035,)\n","y_data_for_network single classification variable (4:8) \t (11035, 3)\n","\n","x_pred rmse\t 0.10800385995681351\n","x_pred r2\t 0.8323426858915761\n","\n","y_pred rmse\t 0.10351965193853203\n","y_pred r2\t 0.8651102253847072\n","\n","z_pred rmse\t 0.05054580819900306\n","z_pred r2\t 0.8288967663635756\n","\n","yaw_pred rmse\t 0.2557824610276006\n","yaw_pred r2\t 0.7989459421199911\n","\n","173/173 [==============================] - 2s 9ms/step - loss: 0.3731 - x_pred_loss: 0.0805 - y_pred_loss: 0.0680 - z_pred_loss: 0.0326 - yaw_pred_loss: 0.1919 - x_pred_mean_squared_error: 0.0117 - y_pred_mean_squared_error: 0.0107 - z_pred_mean_squared_error: 0.0026 - yaw_pred_mean_squared_error: 0.0654\n","\n"," {'loss': 0.3731227517127991, 'x_pred_loss': 0.08054826408624649, 'y_pred_loss': 0.06800096482038498, 'z_pred_loss': 0.03264191746711731, 'yaw_pred_loss': 0.1919315904378891, 'x_pred_mean_squared_error': 0.01166483573615551, 'y_pred_mean_squared_error': 0.010716316290199757, 'z_pred_mean_squared_error': 0.002554879058152437, 'yaw_pred_mean_squared_error': 0.06542465835809708} \n"," \n","\n","Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/MASKRCNN replace 11030 samples TEST (start0, skip10 = 1103) with 20 backgrounds - total 22060/20201022_133340_maskrcnn_replacebg_df22060_1of1.pickle\n","dataset original shape: (22060, 3)\n","dataset keep shape: \t(22060, 3)\n","img_data shape: \t(22060,)\n","x_data shape: \t\t(22060, 60, 108, 3)\n","y_data shape: \t\t(22060, 4)\n","odom_dataset shape: \t(22060, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (22060,)\n","y_data_for_network single classification variable (4:8) \t (22060, 3)\n","\n","x_pred rmse\t 0.3789677708484432\n","x_pred r2\t -1.0649987247326425\n","\n","y_pred rmse\t 0.21427552311226802\n","y_pred r2\t 0.42037653191113\n","\n","z_pred rmse\t 0.12008824633608045\n","z_pred r2\t 0.03927562573655341\n","\n","yaw_pred rmse\t 0.44796930511742816\n","yaw_pred r2\t 0.3829361907027179\n","\n","345/345 [==============================] - 3s 9ms/step - loss: 0.8118 - x_pred_loss: 0.2465 - y_pred_loss: 0.1524 - z_pred_loss: 0.0814 - yaw_pred_loss: 0.3315 - x_pred_mean_squared_error: 0.1436 - y_pred_mean_squared_error: 0.0459 - z_pred_mean_squared_error: 0.0144 - yaw_pred_mean_squared_error: 0.2007\n","\n"," {'loss': 0.8117606043815613, 'x_pred_loss': 0.24647729098796844, 'y_pred_loss': 0.15241029858589172, 'z_pred_loss': 0.08140373229980469, 'yaw_pred_loss': 0.33146947622299194, 'x_pred_mean_squared_error': 0.14361658692359924, 'y_pred_mean_squared_error': 0.04591399058699608, 'z_pred_mean_squared_error': 0.014421185478568077, 'yaw_pred_mean_squared_error': 0.20067648589611053} \n"," \n","\n","Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/MASKRCNN replace 11030 samples TEST (skip2) with single_room11 background - total 5515/20201022_131619_maskrcnn_replacebg_df5515_1of1.pickle\n","dataset original shape: (5515, 3)\n","dataset keep shape: \t(5515, 3)\n","img_data shape: \t(5515,)\n","x_data shape: \t\t(5515, 60, 108, 3)\n","y_data shape: \t\t(5515, 4)\n","odom_dataset shape: \t(5515, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (5515,)\n","y_data_for_network single classification variable (4:8) \t (5515, 3)\n","\n","x_pred rmse\t 0.32962526006320697\n","x_pred r2\t -0.5608422971923555\n","\n","y_pred rmse\t 0.14322648975126065\n","y_pred r2\t 0.7408737588663608\n","\n","z_pred rmse\t 0.09672300228672721\n","z_pred r2\t 0.37378128919778153\n","\n","yaw_pred rmse\t 0.31604869787121864\n","yaw_pred r2\t 0.6928135673679623\n","\n","87/87 [==============================] - 1s 9ms/step - loss: 0.6066 - x_pred_loss: 0.2091 - y_pred_loss: 0.0991 - z_pred_loss: 0.0654 - yaw_pred_loss: 0.2330 - x_pred_mean_squared_error: 0.1087 - y_pred_mean_squared_error: 0.0205 - z_pred_mean_squared_error: 0.0094 - yaw_pred_mean_squared_error: 0.0999\n","\n"," {'loss': 0.6066190004348755, 'x_pred_loss': 0.209084615111351, 'y_pred_loss': 0.09908030927181244, 'z_pred_loss': 0.06544690579175949, 'yaw_pred_loss': 0.23300690948963165, 'x_pred_mean_squared_error': 0.10865281522274017, 'y_pred_mean_squared_error': 0.020513826981186867, 'z_pred_mean_squared_error': 0.009355339221656322, 'yaw_pred_mean_squared_error': 0.09988678246736526} \n"," \n","\n","Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/MASKRCNN replace 11030 samples TEST (skip2) with single_room15 background - total 5515/20201022_131716_maskrcnn_replacebg_df5515_1of1.pickle\n","dataset original shape: (5515, 3)\n","dataset keep shape: \t(5515, 3)\n","img_data shape: \t(5515,)\n","x_data shape: \t\t(5515, 60, 108, 3)\n","y_data shape: \t\t(5515, 4)\n","odom_dataset shape: \t(5515, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (5515,)\n","y_data_for_network single classification variable (4:8) \t (5515, 3)\n","\n","x_pred rmse\t 0.23852747150776993\n","x_pred r2\t 0.18267484863136785\n","\n","y_pred rmse\t 0.1485533912815199\n","y_pred r2\t 0.7212403952253184\n","\n","z_pred rmse\t 0.08665743420565801\n","z_pred r2\t 0.4973355695219842\n","\n","yaw_pred rmse\t 0.3204823047990959\n","yaw_pred r2\t 0.6841345457937551\n","\n","87/87 [==============================] - 1s 9ms/step - loss: 0.5184 - x_pred_loss: 0.1269 - y_pred_loss: 0.1029 - z_pred_loss: 0.0571 - yaw_pred_loss: 0.2314 - x_pred_mean_squared_error: 0.0569 - y_pred_mean_squared_error: 0.0221 - z_pred_mean_squared_error: 0.0075 - yaw_pred_mean_squared_error: 0.1027\n","\n"," {'loss': 0.5183588862419128, 'x_pred_loss': 0.12691769003868103, 'y_pred_loss': 0.10289610177278519, 'z_pred_loss': 0.057129405438899994, 'yaw_pred_loss': 0.23141565918922424, 'x_pred_mean_squared_error': 0.05689534544944763, 'y_pred_mean_squared_error': 0.02206811122596264, 'z_pred_mean_squared_error': 0.007509509101510048, 'yaw_pred_mean_squared_error': 0.10270892828702927} \n"," \n","\n","Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/MASKRCNN replace 11030 samples TEST (skip2) with single_room20 background - total 5515/20201022_131733_maskrcnn_replacebg_df5515_1of1.pickle\n","dataset original shape: (5515, 3)\n","dataset keep shape: \t(5515, 3)\n","img_data shape: \t(5515,)\n","x_data shape: \t\t(5515, 60, 108, 3)\n","y_data shape: \t\t(5515, 4)\n","odom_dataset shape: \t(5515, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (5515,)\n","y_data_for_network single classification variable (4:8) \t (5515, 3)\n","\n","x_pred rmse\t 0.2687735701915768\n","x_pred r2\t -0.03774625547819643\n","\n","y_pred rmse\t 0.15137115073910754\n","y_pred r2\t 0.7105650821774652\n","\n","z_pred rmse\t 0.07799590759886266\n","z_pred r2\t 0.5927977820924115\n","\n","yaw_pred rmse\t 0.35201379637217894\n","yaw_pred r2\t 0.6189224277818002\n","\n","87/87 [==============================] - 1s 9ms/step - loss: 0.5472 - x_pred_loss: 0.1444 - y_pred_loss: 0.0909 - z_pred_loss: 0.0539 - yaw_pred_loss: 0.2579 - x_pred_mean_squared_error: 0.0722 - y_pred_mean_squared_error: 0.0229 - z_pred_mean_squared_error: 0.0061 - yaw_pred_mean_squared_error: 0.1239\n","\n"," {'loss': 0.5471643209457397, 'x_pred_loss': 0.14444279670715332, 'y_pred_loss': 0.090920589864254, 'z_pred_loss': 0.053880978375673294, 'yaw_pred_loss': 0.2579199969768524, 'x_pred_mean_squared_error': 0.0722392275929451, 'y_pred_mean_squared_error': 0.02291322685778141, 'z_pred_mean_squared_error': 0.006083362270146608, 'yaw_pred_mean_squared_error': 0.1239137202501297} \n"," \n","\n","\n","\n","------------------------------------------------\n","\n","Model imported from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-models/prova/regression on bg20 retrain24 - v1_all_class_model.h5 \n","\n","\n","Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/_originals/dario/v1_test.pickle\n","dataset original shape: (11035, 3)\n","dataset keep shape: \t(11035, 3)\n","img_data shape: \t(11035,)\n","x_data shape: \t\t(11035, 60, 108, 3)\n","y_data shape: \t\t(11035, 4)\n","odom_dataset shape: \t(11035, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (11035,)\n","y_data_for_network single classification variable (4:8) \t (11035, 3)\n","\n","x_pred rmse\t 0.13689858786537487\n","x_pred r2\t 0.7306345521322841\n","\n","y_pred rmse\t 0.167675337619334\n","y_pred r2\t 0.646107139039824\n","\n","z_pred rmse\t 0.09078061418118397\n","z_pred r2\t 0.4480825054604608\n","\n","yaw_pred rmse\t 0.30744350015139643\n","yaw_pred r2\t 0.7095295542308151\n","\n","173/173 [==============================] - 2s 9ms/step - loss: 0.5166 - x_pred_loss: 0.1028 - y_pred_loss: 0.1212 - z_pred_loss: 0.0540 - yaw_pred_loss: 0.2385 - x_pred_mean_squared_error: 0.0187 - y_pred_mean_squared_error: 0.0281 - z_pred_mean_squared_error: 0.0082 - yaw_pred_mean_squared_error: 0.0945\n","\n"," {'loss': 0.516572892665863, 'x_pred_loss': 0.10282684117555618, 'y_pred_loss': 0.12122689187526703, 'z_pred_loss': 0.05397452414035797, 'yaw_pred_loss': 0.23854482173919678, 'x_pred_mean_squared_error': 0.018741220235824585, 'y_pred_mean_squared_error': 0.028115013614296913, 'z_pred_mean_squared_error': 0.008241121657192707, 'yaw_pred_mean_squared_error': 0.09452150762081146} \n"," \n","\n","Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/MASKRCNN replace 11030 samples TEST (start0, skip10 = 1103) with 20 backgrounds - total 22060/20201022_133340_maskrcnn_replacebg_df22060_1of1.pickle\n","dataset original shape: (22060, 3)\n","dataset keep shape: \t(22060, 3)\n","img_data shape: \t(22060,)\n","x_data shape: \t\t(22060, 60, 108, 3)\n","y_data shape: \t\t(22060, 4)\n","odom_dataset shape: \t(22060, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (22060,)\n","y_data_for_network single classification variable (4:8) \t (22060, 3)\n","\n","x_pred rmse\t 0.15285840538207865\n","x_pred r2\t 0.6640351184419336\n","\n","y_pred rmse\t 0.11728740792735014\n","y_pred r2\t 0.8263384752324958\n","\n","z_pred rmse\t 0.06095572422105062\n","z_pred r2\t 0.7524705968589105\n","\n","yaw_pred rmse\t 0.2950970190841514\n","yaw_pred r2\t 0.7322292058614832\n","\n","345/345 [==============================] - 3s 9ms/step - loss: 0.4289 - x_pred_loss: 0.1008 - y_pred_loss: 0.0758 - z_pred_loss: 0.0371 - yaw_pred_loss: 0.2151 - x_pred_mean_squared_error: 0.0234 - y_pred_mean_squared_error: 0.0138 - z_pred_mean_squared_error: 0.0037 - yaw_pred_mean_squared_error: 0.0871\n","\n"," {'loss': 0.4289075434207916, 'x_pred_loss': 0.10084517300128937, 'y_pred_loss': 0.07578261196613312, 'z_pred_loss': 0.03712986037135124, 'yaw_pred_loss': 0.21514977514743805, 'x_pred_mean_squared_error': 0.023365696892142296, 'y_pred_mean_squared_error': 0.013756340369582176, 'z_pred_mean_squared_error': 0.0037156022153794765, 'yaw_pred_mean_squared_error': 0.08708223700523376} \n"," \n","\n","Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/MASKRCNN replace 11030 samples TEST (skip2) with single_room11 background - total 5515/20201022_131619_maskrcnn_replacebg_df5515_1of1.pickle\n","dataset original shape: (5515, 3)\n","dataset keep shape: \t(5515, 3)\n","img_data shape: \t(5515,)\n","x_data shape: \t\t(5515, 60, 108, 3)\n","y_data shape: \t\t(5515, 4)\n","odom_dataset shape: \t(5515, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (5515,)\n","y_data_for_network single classification variable (4:8) \t (5515, 3)\n","\n","x_pred rmse\t 0.2102136675996747\n","x_pred r2\t 0.36519556329126224\n","\n","y_pred rmse\t 0.1306324875832433\n","y_pred r2\t 0.7844405370598307\n","\n","z_pred rmse\t 0.05943838929731271\n","z_pred r2\t 0.7635166511611995\n","\n","yaw_pred rmse\t 0.31224308615415625\n","yaw_pred r2\t 0.7001668265842533\n","\n","87/87 [==============================] - 1s 9ms/step - loss: 0.4890 - x_pred_loss: 0.1292 - y_pred_loss: 0.0899 - z_pred_loss: 0.0378 - yaw_pred_loss: 0.2321 - x_pred_mean_squared_error: 0.0442 - y_pred_mean_squared_error: 0.0171 - z_pred_mean_squared_error: 0.0035 - yaw_pred_mean_squared_error: 0.0975\n","\n"," {'loss': 0.4889741837978363, 'x_pred_loss': 0.12917329370975494, 'y_pred_loss': 0.08991537243127823, 'z_pred_loss': 0.037805113941431046, 'yaw_pred_loss': 0.23208041489124298, 'x_pred_mean_squared_error': 0.044189780950546265, 'y_pred_mean_squared_error': 0.01706484518945217, 'z_pred_mean_squared_error': 0.0035329225938767195, 'yaw_pred_mean_squared_error': 0.09749574214220047} \n"," \n","\n","Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/MASKRCNN replace 11030 samples TEST (skip2) with single_room15 background - total 5515/20201022_131716_maskrcnn_replacebg_df5515_1of1.pickle\n","dataset original shape: (5515, 3)\n","dataset keep shape: \t(5515, 3)\n","img_data shape: \t(5515,)\n","x_data shape: \t\t(5515, 60, 108, 3)\n","y_data shape: \t\t(5515, 4)\n","odom_dataset shape: \t(5515, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (5515,)\n","y_data_for_network single classification variable (4:8) \t (5515, 3)\n","\n","x_pred rmse\t 0.18229257816389194\n","x_pred r2\t 0.5226290036830348\n","\n","y_pred rmse\t 0.126678045038952\n","y_pred r2\t 0.7972936265838817\n","\n","z_pred rmse\t 0.0536284347016176\n","z_pred r2\t 0.8074884704232957\n","\n","yaw_pred rmse\t 0.2951163751689621\n","yaw_pred r2\t 0.7321567934328086\n","\n","87/87 [==============================] - 1s 9ms/step - loss: 0.4625 - x_pred_loss: 0.1276 - y_pred_loss: 0.0844 - z_pred_loss: 0.0324 - yaw_pred_loss: 0.2180 - x_pred_mean_squared_error: 0.0332 - y_pred_mean_squared_error: 0.0160 - z_pred_mean_squared_error: 0.0029 - yaw_pred_mean_squared_error: 0.0871\n","\n"," {'loss': 0.4624621570110321, 'x_pred_loss': 0.12758204340934753, 'y_pred_loss': 0.08442911505699158, 'z_pred_loss': 0.032436586916446686, 'yaw_pred_loss': 0.21801437437534332, 'x_pred_mean_squared_error': 0.03323058411478996, 'y_pred_mean_squared_error': 0.01604732684791088, 'z_pred_mean_squared_error': 0.0028760090935975313, 'yaw_pred_mean_squared_error': 0.08709367364645004} \n"," \n","\n","Reading dataset from /content/drive/My Drive/_ USI/_ THESIS/_ Source code/cnn-drone-befree/src/./../dev-datasets/MASKRCNN replace 11030 samples TEST (skip2) with single_room20 background - total 5515/20201022_131733_maskrcnn_replacebg_df5515_1of1.pickle\n","dataset original shape: (5515, 3)\n","dataset keep shape: \t(5515, 3)\n","img_data shape: \t(5515,)\n","x_data shape: \t\t(5515, 60, 108, 3)\n","y_data shape: \t\t(5515, 4)\n","odom_dataset shape: \t(5515, 2)\n","y_data_for_network shape cannot be computed because elements in the list have different shapes:\n","y_data_for_network number of variables \t\t\t\t 8\n","y_data_for_network single regression variable (0:4) \t\t (5515,)\n","y_data_for_network single classification variable (4:8) \t (5515, 3)\n","\n","x_pred rmse\t 0.14861367573763268\n","x_pred r2\t 0.6827251799510294\n","\n","y_pred rmse\t 0.1850637143143318\n","y_pred r2\t 0.5673793478431859\n","\n","z_pred rmse\t 0.05502052467860627\n","z_pred r2\t 0.7973643015596505\n","\n","yaw_pred rmse\t 0.38823020590634605\n","yaw_pred r2\t 0.5364755318249903\n","\n","87/87 [==============================] - 1s 9ms/step - loss: 0.5622 - x_pred_loss: 0.1020 - y_pred_loss: 0.1276 - z_pred_loss: 0.0344 - yaw_pred_loss: 0.2981 - x_pred_mean_squared_error: 0.0221 - y_pred_mean_squared_error: 0.0342 - z_pred_mean_squared_error: 0.0030 - yaw_pred_mean_squared_error: 0.1507\n","\n"," {'loss': 0.5621706247329712, 'x_pred_loss': 0.10204575955867767, 'y_pred_loss': 0.1276414841413498, 'z_pred_loss': 0.03441998362541199, 'yaw_pred_loss': 0.2980634868144989, 'x_pred_mean_squared_error': 0.02208602987229824, 'y_pred_mean_squared_error': 0.034248579293489456, 'z_pred_mean_squared_error': 0.003027258673682809, 'yaw_pred_mean_squared_error': 0.1507226824760437} \n"," \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fpe3T4uueuGQ"},"source":[" "],"execution_count":null,"outputs":[]}]}